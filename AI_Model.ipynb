{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ac-LpH2YqipX"
      },
      "outputs": [],
      "source": [
        "!pip install requests pillow google-api-python-client beautifulsoup4 tqdm pexels_api python-dotenv selenium webdriver-manager\n",
        "!pip install spacy webcolors jsonschema\n",
        "\n",
        "!apt-get update\n",
        "!apt-get install -y wget\n",
        "!wget -q https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "!apt-get install -y ./google-chrome-stable_current_amd64.deb\n",
        "\n",
        "!pip install -q webdriver_manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4qPUPUqq-ar"
      },
      "outputs": [],
      "source": [
        "# Selenium WebDriver Setup\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.chrome.service import Service as ChromeService\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from webdriver_manager.core.os_manager import ChromeType\n",
        "\n",
        "# System & Environment\n",
        "import os\n",
        "import tempfile\n",
        "import time\n",
        "import random\n",
        "import json\n",
        "import zipfile\n",
        "import copy\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "from pprint import pprint\n",
        "import datetime\n",
        "import re\n",
        "\n",
        "# Image\n",
        "from PIL import (\n",
        "    Image,\n",
        "    ImageDraw,\n",
        "    ImageFont,\n",
        "    ImageOps,\n",
        "    ImageColor,\n",
        "    UnidentifiedImageError\n",
        ")\n",
        "from io import BytesIO\n",
        "\n",
        "# Web & API\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from googleapiclient.discovery import build\n",
        "from pexels_api import API as PexelsAPI\n",
        "\n",
        "# NLP & Parsing\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "# Visualization\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from IPython.display import HTML\n",
        "import webcolors\n",
        "from scipy.spatial import KDTree\n",
        "from colorsys import rgb_to_hls\n",
        "from IPython.display import Image as ColabImage, display\n",
        "\n",
        "# Colab\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_colab_driver():\n",
        "    logging.getLogger('WDM').setLevel(logging.NOTSET)\n",
        "\n",
        "    # Chrome Options\n",
        "    options = Options()\n",
        "    options.add_argument(\"--headless=new\")\n",
        "    options.add_argument(\"--no-sandbox\")\n",
        "    options.add_argument(\"--disable-dev-shm-usage\")\n",
        "    options.add_argument(\"--disable-gpu\")\n",
        "    options.add_argument(\"--remote-debugging-port=9222\")\n",
        "    options.add_argument(\"--window-size=1920,1080\")\n",
        "    options.add_argument(\"user-agent=Mozilla/5.0\")\n",
        "\n",
        "    # Binary path check\n",
        "    chrome_path = \"/usr/bin/google-chrome\"\n",
        "    if not os.path.exists(chrome_path):\n",
        "        raise FileNotFoundError(f\"Chrome binary not found at: {chrome_path}\")\n",
        "    options.binary_location = chrome_path\n",
        "\n",
        "    # Temporary user data dir\n",
        "    user_data_dir = tempfile.mkdtemp()\n",
        "    options.add_argument(f\"--user-data-dir={user_data_dir}\")\n",
        "\n",
        "    # Try WebDriver setup\n",
        "    driver = None\n",
        "    try:\n",
        "        service = ChromeService(ChromeDriverManager(chrome_type=ChromeType.GOOGLE).install())\n",
        "        driver = webdriver.Chrome(service=service, options=options)\n",
        "        driver.get(\"https://www.google.com\")\n",
        "        print(f\"WebDriver initialized. Page title: {driver.title}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {e}\")\n",
        "        try:\n",
        "            service = ChromeService(executable_path=\"/usr/bin/chromedriver\")\n",
        "            driver = webdriver.Chrome(service=service, options=options)\n",
        "            driver.get(\"https://www.google.com\")\n",
        "            print(f\"Fallback to system chromedriver. Page title: {driver.title}\")\n",
        "        except Exception as fallback_e:\n",
        "            print(f\"Fallback failed: {fallback_e}\")\n",
        "\n",
        "    return driver"
      ],
      "metadata": {
        "id": "VFGOSNPrLT64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ux0Xs-onxJ64"
      },
      "outputs": [],
      "source": [
        "# Clear old assets\n",
        "for f in os.listdir():\n",
        "    if f.endswith((\".json\", \".png\", \".ttf\")):\n",
        "        try:\n",
        "            os.remove(f)\n",
        "        except Exception as e:\n",
        "            print(f\"Could not remove {f}: {e}\")\n",
        "print(\"Cleared old assets. Remaining files:\", os.listdir())\n",
        "\n",
        "# Required files check\n",
        "required_files = [\"colour.json\", \"emotion_design_dataset.json\", \"Blank Template.png\"]\n",
        "missing_files = [f for f in required_files if not os.path.exists(f)]\n",
        "\n",
        "if missing_files:\n",
        "    print(\" Missing files detected:\")\n",
        "    print(\"- \" + \"\\n- \".join(missing_files))\n",
        "    print(\"Please upload the following:\")\n",
        "    for _ in range(len(missing_files)):\n",
        "        files.upload()\n",
        "else:\n",
        "    print(\"All required base files already present.\")\n",
        "\n",
        "# Load JSON and template image\n",
        "with open(\"colour.json\", \"r\") as f:\n",
        "    color_data = json.load(f)\n",
        "with open(\"emotion_design_dataset.json\", \"r\") as f:\n",
        "    emotion_dataset = json.load(f)\n",
        "\n",
        "template_bg = Image.open(\"Blank Template.png\").convert(\"RGB\")\n",
        "template_bg = template_bg.resize((1080, 1620))\n",
        "\n",
        "# Prepare folders\n",
        "web_ui_folder = \"web_ui\"\n",
        "default_ui_folder = \"default_ui\"\n",
        "os.makedirs(web_ui_folder, exist_ok=True)\n",
        "os.makedirs(default_ui_folder, exist_ok=True)\n",
        "\n",
        "# UI ZIP uploads only if folders are empty\n",
        "zip_upload_needed = (\n",
        "    not os.listdir(web_ui_folder) or\n",
        "    not os.listdir(default_ui_folder)\n",
        ")\n",
        "\n",
        "if zip_upload_needed:\n",
        "    print(\"\\n UI folders are empty. Upload ZIP files:\")\n",
        "    print(\"- One for emotion-specific UI images\")\n",
        "    print(\"- One named 'Default.zip' for default UI assets\")\n",
        "\n",
        "    for _ in range(2):\n",
        "        uploaded = files.upload()\n",
        "        for filename in uploaded:\n",
        "            with tempfile.TemporaryDirectory() as tmpdir:\n",
        "                zip_path = os.path.join(tmpdir, filename)\n",
        "                with open(zip_path, \"wb\") as f:\n",
        "                    f.write(uploaded[filename])\n",
        "                with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "                    target_folder = default_ui_folder if filename.lower().startswith(\"default\") else web_ui_folder\n",
        "                    zip_ref.extractall(target_folder)\n",
        "                    print(f\"Extracted {filename} to: {target_folder}\")\n",
        "else:\n",
        "    print(\" UI folders already populated. Skipping ZIP upload.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anTdtBojI7j0"
      },
      "outputs": [],
      "source": [
        "# Negation and Exclusion Keywords\n",
        "NEGATION_WORDS = {\"not\", \"no\", \"without\", \"except\"}\n",
        "NEGATION_PREFIXES = {\"un\", \"non\", \"dis\", \"a\"}\n",
        "NEGATIVE_ADJ = {\"unfriendly\", \"unpleasant\", \"ugly\", \"unattractive\"}\n",
        "EXCLUSION_VERBS = {\"exclude\", \"remove\", \"omit\", \"avoid\", \"prevent\"}\n",
        "\n",
        "global nlp\n",
        "\n",
        "# NLP Initialization\n",
        "def initialize_nlp():\n",
        "    global spacy\n",
        "    try:\n",
        "        return spacy.load(\"en_core_web_sm\")\n",
        "    except OSError:\n",
        "        import spacy.cli\n",
        "        spacy.cli.download(\"en_core_web_sm\")\n",
        "        return spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def is_negated(span):\n",
        "    if isinstance(span, spacy.tokens.Doc): span = span[:]\n",
        "    if any(token.dep_ == \"neg\" for token in span): return True\n",
        "    if span.start > 0 and span.doc[span.start - 1].lower_ in NEGATION_WORDS: return True\n",
        "    for token in span:\n",
        "        if token.text.lower() in NEGATIVE_ADJ: return True\n",
        "        if token.dep_ in {\"dobj\", \"nsubjpass\", \"pobj\"} and token.head.lemma_ in EXCLUSION_VERBS: return True\n",
        "        for ancestor in token.ancestors:\n",
        "            if ancestor.lemma_ in EXCLUSION_VERBS and token.dep_ in {\"dobj\", \"nsubjpass\", \"pobj\"}: return True\n",
        "        for prefix in NEGATION_PREFIXES:\n",
        "            if token.text.lower().startswith(prefix) and token.pos_ in {\"ADJ\", \"NOUN\"}: return True\n",
        "    return False\n",
        "\n",
        "def adjust_negation_contrast(color_candidates, doc, nlp):\n",
        "    found, negated = set(), set()\n",
        "    for phrase in color_candidates:\n",
        "        span = nlp(phrase)\n",
        "        if is_negated(span): negated.add(phrase)\n",
        "        else: found.add(phrase)\n",
        "    for i, token in enumerate(doc):\n",
        "        if token.lower_ == \"not\":\n",
        "            left_span = doc[max(i - 6, 0):i].text\n",
        "            right_span = doc[i + 1:i + 7].text\n",
        "            for phrase in color_candidates:\n",
        "                if phrase in left_span: found.add(phrase)\n",
        "                elif phrase in right_span: negated.add(phrase)\n",
        "    unassigned = set(color_candidates) - found - negated\n",
        "    found |= unassigned\n",
        "    return sorted(found), sorted(negated)\n",
        "\n",
        "def parse_prompt(prompt, nlp, matcher, color_keywords, pattern_keywords):\n",
        "    doc = nlp(prompt.lower())\n",
        "    explicit_found, explicit_negated, color_phrases = [], [], []\n",
        "\n",
        "    for i in range(len(doc) - 1):\n",
        "        if doc[i].pos_ == \"ADJ\" and doc[i + 1].text in color_keywords:\n",
        "            phrase = f\"{doc[i].text} {doc[i + 1].text}\"\n",
        "            color_phrases.append(phrase)\n",
        "\n",
        "    matches = matcher(doc)\n",
        "    for _, start, end in matches:\n",
        "        span = doc[start:end]\n",
        "        color_phrases.append(span.text.strip())\n",
        "\n",
        "    for color_phrase in color_keywords:\n",
        "        pattern = r'\\b' + re.escape(color_phrase) + r'\\b'\n",
        "        for match in re.finditer(pattern, doc.text):\n",
        "            span = doc.char_span(*match.span(), alignment_mode=\"expand\")\n",
        "            if span:\n",
        "                if is_negated(span): explicit_negated.append(span.text)\n",
        "                else: explicit_found.append(span.text)\n",
        "\n",
        "    for phrase in color_phrases:\n",
        "        if phrase not in explicit_found and phrase not in explicit_negated:\n",
        "            explicit_found.append(phrase)\n",
        "\n",
        "    all_candidates = list(set(explicit_found + explicit_negated))\n",
        "    found_colors, negated_colors = adjust_negation_contrast(all_candidates, doc, nlp)\n",
        "\n",
        "    visuals = []\n",
        "    abstract_terms = {\"mood\", \"emotion\", \"silence\", \"quietness\", \"gentle\", \"soft\", \"subtle\", \"neutral\", \"neutrals\", \"calm\", \"dark\", \"light\"}\n",
        "    for sent in doc.sents:\n",
        "        parts = re.split(r\"[,\\-–—]\", sent.text)\n",
        "        for phrase in parts:\n",
        "            phrase = phrase.strip()\n",
        "            tokens = re.findall(r\"\\b\\w+\\b\", phrase.lower())\n",
        "            is_abstract = any(t in abstract_terms or t in color_keywords for t in tokens)\n",
        "            if len(tokens) >= 2 and not is_abstract and not is_negated(nlp(phrase)):\n",
        "                visuals.append(phrase)\n",
        "\n",
        "    patterns = [kw for kw in pattern_keywords if re.search(r'\\b' + re.escape(kw) + r'\\b', doc.text) and not is_negated(nlp(kw))]\n",
        "\n",
        "    return {\n",
        "        \"colors\": sorted(set(found_colors)),\n",
        "        \"negated_colors\": sorted(set(negated_colors)),\n",
        "        \"visuals\": visuals,\n",
        "        \"patterns\": patterns\n",
        "    }\n",
        "\n",
        "def is_prompt_generic(parsed):\n",
        "    visuals = parsed.get(\"visuals\", [])\n",
        "    patterns = parsed.get(\"patterns\", [])\n",
        "    colors = parsed.get(\"colors\", [])\n",
        "    print(f\"Parsed visuals: {visuals}\")\n",
        "    print(f\"Parsed colors: {colors}\")\n",
        "    print(f\"Parsed patterns: {patterns}\")\n",
        "    if not visuals and not patterns and not colors:\n",
        "        return True\n",
        "    if sum([len(visuals) >= 1, len(colors) >= 1, len(patterns) >= 1]) >= 2:\n",
        "        return False\n",
        "    if len(visuals) == 0 and len(colors) <= 1 and len(patterns) == 0:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def sanitize_emotion_label(label):\n",
        "    label = label.strip().upper()\n",
        "    return re.sub(r'[\\s\\-_\\/]+', '/', label)\n",
        "\n",
        "def merge_prompt_with_spec(parsed_data, emotion_dataset, label):\n",
        "    base = copy.deepcopy(emotion_dataset.get(label, {}))\n",
        "    if not base:\n",
        "        print(f\"Warning: Emotion label '{label}' not found in dataset. Using empty base.\")\n",
        "        base = { \"colors\": [], \"images_keywords\": [], \"pattern\": \"\" }\n",
        "\n",
        "    parsed_colors = parsed_data.get(\"colors\", [])\n",
        "    if parsed_colors and isinstance(parsed_colors[0], dict):\n",
        "        base[\"colors\"] = parsed_colors\n",
        "\n",
        "    abstract_terms = {\n",
        "        \"texture\", \"pattern\", \"emotion\", \"tone\", \"feeling\", \"expression\",\n",
        "        \"mood\", \"moodboard\", \"quietness\", \"emptiness\", \"lighting\", \"shadow\"\n",
        "    }\n",
        "\n",
        "    def is_visual_clean(phrase):\n",
        "        tokens = re.findall(r\"\\b\\w+\\b\", phrase.lower())\n",
        "        return not any(t in abstract_terms for t in tokens)\n",
        "\n",
        "    visuals_parsed = [v for v in parsed_data.get(\"visuals\", []) if is_visual_clean(v)]\n",
        "    visuals_json = [v for v in base.get(\"images_keywords\", []) if is_visual_clean(v)]\n",
        "\n",
        "    def get_base_tokens(phrase):\n",
        "        return set(re.findall(r\"\\b\\w+\\b\", phrase.lower()))\n",
        "\n",
        "    selected_visuals = []\n",
        "    candidate_pool = visuals_parsed + visuals_json\n",
        "    random.shuffle(candidate_pool)\n",
        "\n",
        "    for phrase in candidate_pool:\n",
        "        current_tokens = get_base_tokens(phrase)\n",
        "        if all(len(current_tokens.intersection(get_base_tokens(existing))) <= 1 for existing in selected_visuals):\n",
        "            selected_visuals.append(phrase)\n",
        "        if len(selected_visuals) >= 4:\n",
        "            break\n",
        "\n",
        "    base[\"all_images_keywords\"] = candidate_pool\n",
        "    base[\"images_keywords\"] = selected_visuals\n",
        "\n",
        "    patterns = parsed_data.get(\"patterns\", [])\n",
        "    if patterns:\n",
        "        base[\"pattern\"] = patterns[0]\n",
        "\n",
        "    print(f\"Merged spec: {json.dumps(base, indent=2)}\")\n",
        "    return base\n",
        "\n",
        "def tweak_assets(spec, new_data):\n",
        "    for key in ['colors', 'visuals', 'patterns']:\n",
        "        if new_data.get(key):\n",
        "            spec[key] = list(set(spec.get(key, [])) | set(new_data[key]))\n",
        "    return spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2j-HhLzJ4Tt"
      },
      "outputs": [],
      "source": [
        "def font(emotion_label, dataset_path=\"emotion_design_dataset.json\", out_dir=\"/tmp/fonts\"):\n",
        "    FALLBACK_FONT = \"https://fonts.gstatic.com/s/opensans/v18/mem8YaGs126MiZpBA-UFVZ0bf8pkAg.woff2\"\n",
        "    GOOGLE_FONTS_API_KEY = \"Google Font API Key",
        "\n",
        "    FONT_URL_OVERRIDES = {\n",
        "        \"Poppins\": \"https://fonts.gstatic.com/s/poppins/v20/pxiGyp8kv8JHgFVrJJfedw.woff2\",\n",
        "        \"Open Sans\": \"https://fonts.gstatic.com/s/opensans/v18/mem8YaGs126MiZpBA-UFVZ0bf8pkAg.woff2\"\n",
        "    }\n",
        "\n",
        "    def sanitize_font_filename(name):\n",
        "        return \"\".join(c for c in name if c.isalnum()).lower()\n",
        "\n",
        "    def sanitize_emotion_label(label):\n",
        "        return re.sub(r'[\\s\\-_\\/]+', '/', label.strip().upper())\n",
        "\n",
        "    def build_fonts_service():\n",
        "        return build(\"webfonts\", \"v1\", developerKey=GOOGLE_FONTS_API_KEY)\n",
        "\n",
        "    def fetch_font_url(font_name):\n",
        "        if font_name in FONT_URL_OVERRIDES:\n",
        "            return FONT_URL_OVERRIDES[font_name]\n",
        "        try:\n",
        "            service = build_fonts_service()\n",
        "            fonts = service.webfonts().list().execute().get(\"items\", [])\n",
        "            for font in fonts:\n",
        "                if font[\"family\"].lower() == font_name.lower():\n",
        "                    files = font.get(\"files\", {})\n",
        "                    return files.get(\"regular\") or next((url for url in files.values() if \".ttf\" in url.lower()), None)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to fetch '{font_name}' from API: {e}\")\n",
        "        return None\n",
        "\n",
        "    def download_font(name, url):\n",
        "        slug = sanitize_font_filename(name)\n",
        "        path = os.path.join(out_dir, f\"{slug}.ttf\")\n",
        "        if os.path.exists(path):\n",
        "            print(f\"✔ Cached: {name} → {path}\")\n",
        "            return path\n",
        "        try:\n",
        "            os.makedirs(out_dir, exist_ok=True)\n",
        "            response = requests.get(url, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            with open(path, \"wb\") as f:\n",
        "                f.write(response.content)\n",
        "            print(f\"✔ Downloaded: {name} → {path}\")\n",
        "            return path\n",
        "        except Exception as e:\n",
        "            print(f\"Download failed for '{name}': {e}\")\n",
        "            return FALLBACK_FONT\n",
        "\n",
        "    def prepare(font_meta):\n",
        "        font_paths = {}\n",
        "        for role, meta in font_meta.items():\n",
        "            font_name = meta.get(\"name\")\n",
        "            if not font_name:\n",
        "                print(f\"Missing font name for {role} — fallback used\")\n",
        "                font_paths[role] = FALLBACK_FONT\n",
        "                continue\n",
        "            print(f\"Resolving font: {font_name} ({role})\")\n",
        "            font_url = fetch_font_url(font_name) or meta.get(\"url\")\n",
        "            font_paths[role] = download_font(font_name, font_url) if font_url else FALLBACK_FONT\n",
        "        return font_paths\n",
        "\n",
        "    # Main logic\n",
        "    with open(dataset_path) as f:\n",
        "        raw = json.load(f)\n",
        "    dataset = {sanitize_emotion_label(k): v for k, v in raw.items()}\n",
        "    label = sanitize_emotion_label(emotion_label)\n",
        "\n",
        "    if label not in dataset:\n",
        "        fallback = next((k for k in dataset if k.lower() == label.lower()), None)\n",
        "        if fallback:\n",
        "            label = fallback\n",
        "            print(f\"Using fallback label: {fallback}\")\n",
        "        else:\n",
        "            print(f\"Emotion label '{emotion_label}' not found\")\n",
        "            return {}\n",
        "\n",
        "    font_meta = {}\n",
        "    font_url_map = dataset[label].get(\"font_url\", {})\n",
        "    for role in [\"headings\", \"body_text\", \"highlight_text\"]:\n",
        "        raw_label = dataset[label][\"fonts\"].get(role, \"\")\n",
        "        font_name = raw_label.split(\" (\")[0].strip()\n",
        "        if font_name:\n",
        "            font_meta[role] = {\n",
        "                \"name\": font_name,\n",
        "                \"url\": font_url_map.get(font_name)\n",
        "            }\n",
        "\n",
        "    print(f\"\\nLoading fonts for: {label}\")\n",
        "    return prepare(font_meta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQaLMO2RJ6IE"
      },
      "outputs": [],
      "source": [
        "def image(merged_spec, emotion_label, api_key, colour_json_path=\"colour.json\", save_dir=\"images\"):\n",
        "    def build_color_lookup(path):\n",
        "        with open(path, \"r\") as f:\n",
        "            col = json.load(f)\n",
        "        name2rgb, vocab = {}, set()\n",
        "        for group in col.values():\n",
        "            for name in group:\n",
        "                try:\n",
        "                    name2rgb[name] = ImageColor.getrgb(name)\n",
        "                except:\n",
        "                    continue\n",
        "        for name in name2rgb:\n",
        "            c = name.lower()\n",
        "            vocab.update([c, c + \"s\", c + \"es\"])\n",
        "            if c.endswith(\"y\"):\n",
        "                vocab.add(c[:-1] + \"ies\")\n",
        "        vocab.update([\n",
        "            \"greys\", \"grays\", \"pinks\", \"blacks\", \"whites\", \"nudes\", \"pastels\", \"earthtones\",\n",
        "            \"reds\", \"blues\", \"yells\", \"beiges\", \"greens\", \"oranges\"\n",
        "        ])\n",
        "        rgb_norm = [tuple(c / 255 for c in name2rgb[name]) for name in name2rgb]\n",
        "        tree = KDTree(rgb_norm)\n",
        "        return tree, list(name2rgb.keys()), name2rgb, vocab\n",
        "\n",
        "    def is_safe_image(src: str, alt: str) -> bool:\n",
        "        src, alt = src.lower(), alt.lower()\n",
        "        unsafe_keywords = [\n",
        "            \"cover\", \"thumbnail\", \"video\", \"youtube\", \"vimeo\", \"play button\",\n",
        "            \"logo\", \"svg\", \"ad\", \"template\", \"banner\", \"product\", \"shop\", \"sale\",\n",
        "            \"explicit\", \"provocative\", \"sensual\", \"lingerie\", \"nude\", \"sex\"\n",
        "        ]\n",
        "        return not any(bad in src or bad in alt for bad in unsafe_keywords)\n",
        "\n",
        "    def save_image(url, path):\n",
        "        if \"s.pinimg.com/webapp\" in url:\n",
        "            return False\n",
        "        try:\n",
        "            response = requests.get(url, timeout=10, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "            if \"image\" not in response.headers.get(\"Content-Type\", \"\"):\n",
        "                return False\n",
        "            img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "            img.save(path)\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to save image: {e}\")\n",
        "            return False\n",
        "\n",
        "    def try_save_from_pool(urls, path):\n",
        "        for url in urls:\n",
        "            if save_image(url, path):\n",
        "                return True\n",
        "        print(\"No good image found in pool\")\n",
        "        return False\n",
        "\n",
        "    def fetch_pinterest(phrase, color, count=8):\n",
        "        options = Options()\n",
        "        options.add_argument(\"--headless\")\n",
        "        options.add_argument(\"--no-sandbox\")\n",
        "        options.add_argument(\"--disable-dev-shm-usage\")\n",
        "        options.add_argument(\"--disable-gpu\")\n",
        "        options.add_argument(\"--remote-debugging-port=9222\")\n",
        "        options.binary_location = \"/usr/bin/google-chrome\"\n",
        "        options.add_argument(\"--window-size=1920,1080\")\n",
        "        options.add_argument(\"user-agent=Mozilla/5.0\")\n",
        "\n",
        "        driver = None\n",
        "        try:\n",
        "            service = ChromeService(ChromeDriverManager(chrome_type=ChromeType.GOOGLE).install())\n",
        "            driver = webdriver.Chrome(service=service, options=options)\n",
        "        except Exception as e:\n",
        "            print(f\"WebDriverManager failed: {e}\")\n",
        "            try:\n",
        "                service = ChromeService(executable_path=\"/usr/bin/chromedriver\")\n",
        "                driver = webdriver.Chrome(service=service, options=options)\n",
        "            except Exception as fallback_e:\n",
        "                print(f\"System chromedriver fallback failed: {fallback_e}\")\n",
        "                return []\n",
        "\n",
        "        emotion_tags = {\n",
        "            \"LOVE\": [\"romantic\", \"tender\"], \"JOY/HAPPINESS\": [\"bright\", \"cheerful\"],\n",
        "            \"POWER/ANGER\": [\"bold\", \"fiery\"], \"PEACE/SERENITY\": [\"tranquil\", \"gentle\"]\n",
        "        }.get(emotion_label.upper(), [])\n",
        "\n",
        "        query = '+'.join(filter(None, [phrase, color] + emotion_tags + [emotion_label.lower()]))\n",
        "        search_url = f\"https://www.pinterest.com/search/pins/?q={query}\"\n",
        "\n",
        "        try:\n",
        "            driver.get(search_url)\n",
        "            time.sleep(3)\n",
        "            images = []\n",
        "            for i in range(40):\n",
        "                try:\n",
        "                    pins = driver.find_elements(By.TAG_NAME, \"img\")\n",
        "                    if i >= len(pins):\n",
        "                        break\n",
        "                    pin = pins[i]\n",
        "                    src = pin.get_attribute(\"src\")\n",
        "                    alt = (pin.get_attribute(\"alt\") or \"\")\n",
        "                    if not src or \"s.pinimg.com/webapp\" in src:\n",
        "                        continue\n",
        "                    if not is_safe_image(src, alt):\n",
        "                        continue\n",
        "                    if any(c in f\"{src} {alt}\".lower() for c in color_vocab_all):\n",
        "                        continue\n",
        "                    images.append(src)\n",
        "                    if len(images) >= count:\n",
        "                        break\n",
        "                except Exception as e:\n",
        "                    print(\"Skipping stale image:\", e)\n",
        "                    continue\n",
        "            return images\n",
        "        except Exception as e:\n",
        "            print(f\"Error scraping Pinterest: {e}\")\n",
        "            return []\n",
        "        finally:\n",
        "            if driver:\n",
        "                driver.quit()\n",
        "\n",
        "    def fetch_pexels(phrase, color, count=8):\n",
        "        client = PexelsAPI(api_key)\n",
        "        client.search(f\"{phrase} {color} atmosphere\", page=1, results_per_page=count)\n",
        "        raw_entries = client.get_entries()\n",
        "        safe_urls = [p.original for p in raw_entries if is_safe_image(p.original, getattr(p, \"alt\", \"\"))]\n",
        "        return safe_urls[:count]\n",
        "\n",
        "    def fetch_images(phrase, color, count=8):\n",
        "        results = fetch_pinterest(phrase, color, count)\n",
        "        if len(results) < count:\n",
        "            print(\"Pinterest low yield → fallback to Pexels\")\n",
        "            results += fetch_pexels(phrase, color, count - len(results))\n",
        "        return results[:count]\n",
        "\n",
        "    tree, color_names, name2rgb, color_vocab_all = build_color_lookup(colour_json_path)\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    keywords = merged_spec.get(\"images_keywords\", [])[:4]\n",
        "    colors = merged_spec.get(\"colors\", [])[:5]\n",
        "    pattern = merged_spec.get(\"pattern\", \"\")\n",
        "    while len(keywords) < 4:\n",
        "        keywords.append(\"texture shadow\")\n",
        "    while len(colors) < 5:\n",
        "        colors.append({\"hex\": \"#CCCCCC\", \"hue_group\": \"gray\"})\n",
        "\n",
        "    saved_paths = []\n",
        "\n",
        "    for i, phrase in enumerate(keywords):\n",
        "        color_name = colors[random.randint(0, 4)].get(\"hue_group\", \"gray\")\n",
        "        urls = fetch_images(phrase, color_name, count=8)\n",
        "        path = os.path.join(save_dir, f\"keyword_{i+1}.jpg\")\n",
        "        if try_save_from_pool(urls, path):\n",
        "            saved_paths.append(path)\n",
        "\n",
        "    pattern_color = colors[random.choice([1, 2, 3])].get(\"hue_group\", \"gray\")\n",
        "    urls = fetch_images(pattern, pattern_color, count=8)\n",
        "    pattern_path = os.path.join(save_dir, \"pattern.jpg\")\n",
        "    if try_save_from_pool(urls, pattern_path):\n",
        "        saved_paths.append(pattern_path)\n",
        "        merged_spec[\"pattern_path\"] = pattern_path\n",
        "\n",
        "    merged_spec[\"image_paths\"] = saved_paths\n",
        "    merged_spec[\"pattern_path\"] = pattern_path\n",
        "    return merged_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8p1yMGuFNIK7"
      },
      "outputs": [],
      "source": [
        "def moodboard(spec, emotion_label, template_bg, emotion_dataset):\n",
        "    # Ensure template is correct size\n",
        "    if template_bg.size != (1080, 1620):\n",
        "        template_bg = template_bg.resize((1080, 1620))\n",
        "\n",
        "    FALLBACK_FONT_PATH = spec[\"font_paths\"].get(\"headings\")\n",
        "    def clean_label(label):\n",
        "        return re.sub(r\"\\W+\", \"\", label.replace(\"/\", \"_\").strip())\n",
        "\n",
        "    def get_open_sans_font(size=18):\n",
        "        try:\n",
        "            path = spec[\"font_paths\"].get(\"body_text\", FALLBACK_FONT_PATH)\n",
        "            return ImageFont.truetype(path, size=size)\n",
        "        except Exception:\n",
        "            return ImageFont.load_default()\n",
        "\n",
        "    # Define zones for 1080x1620 output\n",
        "    raw_zones = [\n",
        "        (551, 496, 529, 601),\n",
        "        (804, 1271, 276, 349),\n",
        "        (361, 1271, 423, 349),\n",
        "        (0, 1120, 341, 500),\n",
        "        (0, 0, 535, 496),\n",
        "        (551, 0, 529, 469)\n",
        "    ]\n",
        "    image_zones = [(x, y, x + w, y + h) for (x, y, w, h) in raw_zones]\n",
        "    color_zones = [\n",
        "        (360, 1120, 488, 1248),\n",
        "        (508, 1120, 636, 1248),\n",
        "        (656, 1120, 784, 1248),\n",
        "        (804, 1120, 932, 1248),\n",
        "        (952, 1120, 1080, 1248)\n",
        "    ]\n",
        "    font_block_zone = (0, 628, 530, 1097)  # Adjust if you need wider/narrower font area\n",
        "\n",
        "    canvas = template_bg.copy()\n",
        "    draw = ImageDraw.Draw(canvas)\n",
        "\n",
        "    # Paste images\n",
        "    def paste_and_crop(img_path, target_box, canvas):\n",
        "        try:\n",
        "            img = Image.open(img_path).convert(\"RGB\")\n",
        "            img = ImageOps.fit(\n",
        "                img,\n",
        "                (target_box[2] - target_box[0], target_box[3] - target_box[1]),\n",
        "                Image.Resampling.LANCZOS\n",
        "            )\n",
        "            canvas.paste(img, (target_box[0], target_box[1]))\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to paste image '{img_path}': {e}\")\n",
        "\n",
        "    for i, path in enumerate(spec.get(\"image_paths\", [])[:4]):\n",
        "        paste_and_crop(path, image_zones[i], canvas)\n",
        "\n",
        "    # Pattern\n",
        "    pattern_path = spec.get(\"pattern_path\")\n",
        "    if pattern_path and os.path.exists(pattern_path):\n",
        "        paste_and_crop(pattern_path, image_zones[4], canvas)\n",
        "\n",
        "    # Website UI\n",
        "    ui_filename = spec.get(\"website_ui\", \"\")\n",
        "    ui_path = os.path.join(\"web_ui\", ui_filename)\n",
        "    if ui_filename and os.path.isfile(ui_path):\n",
        "        paste_and_crop(ui_path, image_zones[5], canvas)\n",
        "\n",
        "    # Colors\n",
        "    for zone, color_obj in zip(color_zones, spec.get(\"colors\", [])):\n",
        "        hex_code = color_obj[\"hex\"] if isinstance(color_obj, dict) else color_obj\n",
        "        try:\n",
        "            rgb = tuple(int(hex_code.lstrip(\"#\")[i:i+2], 16) for i in (0, 2, 4))\n",
        "        except:\n",
        "            rgb = (200, 200, 200)\n",
        "        draw.rectangle(zone, fill=rgb)\n",
        "\n",
        "    # Font block\n",
        "    bg_rgb = tuple(int(spec[\"font_bg_color\"].lstrip(\"#\")[i:i+2], 16) for i in (0, 2, 4))\n",
        "    fg_rgb = tuple(int(spec[\"font_color\"].lstrip(\"#\")[i:i+2], 16) for i in (0, 2, 4))\n",
        "    draw.rectangle(font_block_zone, fill=bg_rgb)\n",
        "\n",
        "    # Title Font\n",
        "    main_title = emotion_label.upper()\n",
        "    try:\n",
        "        title_font_path = spec[\"font_paths\"].get(\"headings\", FALLBACK_FONT_PATH)\n",
        "        main_font = ImageFont.truetype(title_font_path, size=55)\n",
        "    except Exception:\n",
        "        main_font = get_open_sans_font(size=55)\n",
        "    title_bbox = draw.textbbox((0, 0), main_title, font=main_font)\n",
        "    title_x = font_block_zone[0] + (font_block_zone[2] - font_block_zone[0]) // 2 - (title_bbox[2] - title_bbox[0]) // 2\n",
        "    title_y = font_block_zone[1] - 110\n",
        "    draw.text((title_x, title_y), main_title, fill=\"black\", font=main_font)\n",
        "\n",
        "    fonts = spec.get(\"fonts\", {})\n",
        "    font_paths = spec.get(\"font_paths\", {})\n",
        "    samples = emotion_dataset.get(emotion_label, {}).get(\"samples\", {})\n",
        "\n",
        "    try:\n",
        "        label_font_path = font_paths.get(\"body_text\", FALLBACK_FONT_PATH)\n",
        "        label_font = ImageFont.truetype(label_font_path, size=18)\n",
        "    except Exception:\n",
        "        label_font = get_open_sans_font(size=18)\n",
        "\n",
        "    y_cursor = font_block_zone[1] + 32\n",
        "    max_y = font_block_zone[3] - 40\n",
        "\n",
        "    for style in [\"headings\", \"body_text\", \"highlight_text\"]:\n",
        "        descriptor = samples.get(style, \"\").strip()\n",
        "        font_name = fonts.get(style, \"Unnamed\")\n",
        "        font_path = font_paths.get(style, font_paths.get(\"headings\"))\n",
        "        if not font_path:\n",
        "            continue\n",
        "        try:\n",
        "            sample_font = ImageFont.truetype(font_path, size=60)\n",
        "        except Exception:\n",
        "            sample_font = get_open_sans_font(size=60)\n",
        "\n",
        "        label_line = f\"{font_name} ({descriptor})\" if descriptor else font_name\n",
        "        label_bbox = draw.textbbox((0, 0), label_line, font=label_font)\n",
        "        label_x = font_block_zone[0] + (font_block_zone[2] - font_block_zone[0]) // 2 - (label_bbox[2] - label_bbox[0]) // 2\n",
        "        draw.text((label_x, y_cursor), label_line, fill=fg_rgb, font=label_font)\n",
        "        y_cursor += label_bbox[3] - label_bbox[1] + 14\n",
        "\n",
        "        emotion_key = emotion_label.split('/')[0].strip().capitalize()\n",
        "        sample_line = f\"Feel The {emotion_key}\"\n",
        "        sample_bbox = draw.textbbox((0, 0), sample_line, font=sample_font)\n",
        "        sample_x = font_block_zone[0] + (font_block_zone[2] - font_block_zone[0]) // 2 - (sample_bbox[2] - sample_bbox[0]) // 2\n",
        "        draw.text((sample_x, y_cursor), sample_line, fill=fg_rgb, font=sample_font)\n",
        "        y_cursor += sample_bbox[3] - sample_bbox[1] + 30\n",
        "\n",
        "        if y_cursor > max_y:\n",
        "            break\n",
        "\n",
        "    return canvas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_user_overrides(user_prompt: str, visual_spec: dict) -> dict:\n",
        "\n",
        "    prompt = user_prompt.lower()\n",
        "\n",
        "    # Replace image keyword logic\n",
        "    img_replace = re.findall(r'replace\\s+(\\w+)\\s+with\\s+(\\w+)', prompt)\n",
        "    for old_img, new_img in img_replace:\n",
        "        for key, value in visual_spec.items():\n",
        "            if value == old_img:\n",
        "                visual_spec[key] = new_img\n",
        "                print(f\"Replaced image '{old_img}' with '{new_img}' in '{key}'.\")\n",
        "\n",
        "    # Color override\n",
        "    hex_match = re.search(r'use this colour\\s+(#[0-9a-fA-F]{6})', prompt)\n",
        "    if hex_match:\n",
        "        visual_spec[\"accent_color\"] = hex_match.group(1)\n",
        "        print(f\"Accent color overridden to '{hex_match.group(1)}'.\")\n",
        "\n",
        "    # Use specific image\n",
        "    visual_match = re.findall(r'use this visual\\s+(\\w+)', prompt)\n",
        "    for new_visual in visual_match:\n",
        "        visual_spec[\"main_img\"] = new_visual\n",
        "        print(f\"🔧 Main visual replaced with '{new_visual}'.\")\n",
        "\n",
        "    # Emotion or tone prompts\n",
        "    tone_map = {\n",
        "        \"calm\": \"#A2D5F2\", \"warm\": \"#FFB366\", \"bold\": \"#FF3E3E\", \"serene\": \"#B9E3C6\",\n",
        "        \"playful\": \"#FFC8E4\", \"dramatic\": \"#222222\"\n",
        "    }\n",
        "    for tone in tone_map:\n",
        "        if f\"make it more {tone}\" in prompt or f\"add {tone} tone\" in prompt:\n",
        "            visual_spec[\"accent_color\"] = tone_map[tone]\n",
        "            print(f\"Emotional tone set to '{tone}' → Color: {tone_map[tone]}\")\n",
        "\n",
        "    # Exclude element\n",
        "    exclude_match = re.findall(r'remove (\\w+)', prompt)\n",
        "    for element in exclude_match:\n",
        "        for key in list(visual_spec.keys()):\n",
        "            if visual_spec[key] == element or key == element:\n",
        "                visual_spec.pop(key)\n",
        "                print(f\"Removed element '{element}' from spec.\")\n",
        "\n",
        "    # Include directive\n",
        "    include_match = re.findall(r'include (\\w+)', prompt)\n",
        "    for asset in include_match:\n",
        "        visual_spec[f\"custom_{asset}\"] = asset\n",
        "        print(f\"Included '{asset}' as 'custom_{asset}' in spec.\")\n",
        "\n",
        "    return visual_spec\n",
        "\n",
        "\n",
        "def run_override_prompt(spec, emotion_label, template_bg, emotion_dataset, session_dir, count):\n",
        "    from IPython.display import clear_output\n",
        "    import ipywidgets as widgets\n",
        "\n",
        "    # UI Components\n",
        "    override_toggle = widgets.ToggleButtons(\n",
        "        options=['yes', 'no'],\n",
        "        description='Specify overrides?',\n",
        "        button_style='info'\n",
        "    )\n",
        "\n",
        "    directive_box = widgets.Text(\n",
        "        placeholder='Type your override (e.g. replace X with Y)',\n",
        "        description='Directive:',\n",
        "        layout=widgets.Layout(width='100%')\n",
        "    )\n",
        "\n",
        "    apply_btn = widgets.Button(\n",
        "        description='Apply Override',\n",
        "        button_style='success',\n",
        "        icon='check'\n",
        "    )\n",
        "\n",
        "    output_area = widgets.Output()\n",
        "\n",
        "    # Apply Button Logic\n",
        "    def on_apply_click(_):\n",
        "        directive = directive_box.value.strip()\n",
        "        with output_area:\n",
        "            clear_output()\n",
        "            if directive:\n",
        "                updated = apply_user_overrides(directive, spec)\n",
        "                canvas_bg = template_bg.copy()\n",
        "                output_img = moodboard(updated, emotion_label, canvas_bg, emotion_dataset)\n",
        "                output_path = os.path.join(session_dir, f\"moodboard_{count}_override.png\")\n",
        "                output_img.save(output_path)\n",
        "                print(f\"Override moodboard saved to: {output_path}\")\n",
        "                display(ColabImage(filename=output_path, width=300))\n",
        "            else:\n",
        "                print(\"No override directive provided.\")\n",
        "\n",
        "    # Toggle Button Logic\n",
        "    def on_toggle(change):\n",
        "        clear_output(wait=True)\n",
        "        display(override_toggle)\n",
        "        output_area.clear_output()\n",
        "        if change['new'] == 'yes':\n",
        "            display(widgets.VBox([directive_box, apply_btn, output_area]))\n",
        "        else:\n",
        "            with output_area:\n",
        "                print(\"No overrides applied.\")\n",
        "\n",
        "    apply_btn.on_click(on_apply_click)\n",
        "    override_toggle.observe(on_toggle, names='value')\n",
        "\n",
        "    display(override_toggle)"
      ],
      "metadata": {
        "id": "Jp_4wv09YKdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZJMgQTIOeou"
      },
      "outputs": [],
      "source": [
        "def run(emotion_label, color_data, emotion_dataset, template_bg):\n",
        "\n",
        "    api_key = \"Pexel API Key",
        "\n",
        "    # NLP Setup\n",
        "    nlp = initialize_nlp()\n",
        "    matcher = Matcher(nlp.vocab)\n",
        "    matcher.add(\"IMPLICIT_COLOR_NOUN_COLOR\", [[{\"POS\": \"NOUN\"}, {\"LOWER\": \"color\"}]])\n",
        "    matcher.add(\"IMPLICIT_COLOR_COLOR_OF_NOUN\", [[{\"LOWER\": \"color\"}, {\"LOWER\": \"of\"}, {\"POS\": \"DET\", \"OP\": \"?\"}, {\"POS\": \"NOUN\"}]])\n",
        "    matcher.add(\"IMPLICIT_COLOR_SHADE_OF\", [[{\"LOWER\": {\"IN\": [\"shade\", \"tone\", \"hue\", \"tint\"]}}, {\"LOWER\": \"of\"}, {\"POS\": \"DET\", \"OP\": \"?\"}, {\"POS\": \"NOUN\"}]])\n",
        "\n",
        "    # Vocabulary Prep\n",
        "    color_keywords = [c.lower() for group in color_data.values() for c in group]\n",
        "    pattern_keywords = [\"floral\", \"stripes\", \"polka dots\", \"abstract\", \"geometric\", \"waves\"]\n",
        "\n",
        "    sanitized_label = sanitize_emotion_label(emotion_label)\n",
        "    session_dir = tempfile.mkdtemp()\n",
        "    print(f\"Session assets will be stored in: {session_dir}\")\n",
        "\n",
        "    font_paths = font(emotion_label)\n",
        "    prompt = input(\"Enter a visual prompt: \").strip()\n",
        "\n",
        "    parsed = parse_prompt(prompt, nlp, matcher, color_keywords, pattern_keywords)\n",
        "    print(\"Parsed result:\")\n",
        "    print(json.dumps(parsed, indent=2))\n",
        "\n",
        "    # Fallback Handling\n",
        "    if is_prompt_generic(parsed):\n",
        "        moodboard_file = emotion_dataset.get(sanitized_label, {}).get(\"moodboard\")\n",
        "        if moodboard_file:\n",
        "            moodboard_path = os.path.join(\"default_ui\", moodboard_file)\n",
        "            if os.path.exists(moodboard_path):\n",
        "                output_path = os.path.join(session_dir, \"moodboard_default.png\")\n",
        "                Image.open(moodboard_path).save(output_path)\n",
        "                print(f\"Fallback moodboard saved to: {output_path}\")\n",
        "                display(ColabImage(filename=output_path, width=300))\n",
        "            else:\n",
        "                print(f\"Fallback moodboard '{moodboard_file}' not found.\")\n",
        "        else:\n",
        "            print(f\"No fallback moodboard found for '{sanitized_label}'\")\n",
        "        return None\n",
        "\n",
        "    # Moodboard Spec & Rendering\n",
        "    spec = merge_prompt_with_spec(parsed, emotion_dataset, sanitized_label)\n",
        "    spec[\"font_paths\"] = font_paths\n",
        "    spec = image(spec, emotion_label, api_key)\n",
        "\n",
        "    canvas_bg = template_bg.copy()\n",
        "    output_img = moodboard(spec, emotion_label, canvas_bg, emotion_dataset)\n",
        "    output_path = os.path.join(session_dir, \"moodboard.png\")\n",
        "    output_img.save(output_path)\n",
        "    print(f\"Moodboard saved to: {output_path}\")\n",
        "    display(ColabImage(filename=output_path, width=300))\n",
        "\n",
        "    return spec, emotion_label, template_bg, emotion_dataset, session_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eV_ycjl4OwlS"
      },
      "outputs": [],
      "source": [
        "_ = run(emotion_label, color_data, emotion_dataset, template_bg)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spec_context = run(emotion_label, color_data, emotion_dataset, template_bg)\n",
        "\n",
        "if spec_context:\n",
        "    spec, emotion_label, template_bg, emotion_dataset, session_dir = spec_context\n",
        "    run_override_prompt(spec, emotion_label, template_bg, emotion_dataset, session_dir, count=1)"
      ],
      "metadata": {
        "id": "nyds5Ezty-Im"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
